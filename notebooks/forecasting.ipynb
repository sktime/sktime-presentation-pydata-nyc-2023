{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97609c33",
   "metadata": {},
   "source": [
    "# Forecasting With Classical and Machine Learning Methods Using sktime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3dfb5e",
   "metadata": {},
   "source": [
    "### What is Forecasting?\n",
    "\n",
    "Forecasting is the process of making predictions about future events or trends by analyzing past and present data.\n",
    "\n",
    "Forecasts are built by studying time series data.\n",
    "\n",
    "What is time series data?\n",
    "\n",
    "time series = recorded observations of one object or process at different time points.\n",
    "\n",
    "observations at different time points are of same kind/type.\n",
    "\n",
    "observations recorded with time index (= recorded time stamp)\n",
    "\n",
    "![](../images/problem_statement.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ddc001",
   "metadata": {},
   "source": [
    "![](../images/presentation_agenda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7ebd6",
   "metadata": {},
   "source": [
    "![](../images/time_series_definition.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55063bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sktime.datasets import load_shampoo_sales\n",
    "\n",
    "y = load_shampoo_sales()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c067b3",
   "metadata": {},
   "source": [
    "What makes time series problems unique?  \n",
    "\n",
    "sequentiality, auto-correlation!\n",
    "\n",
    "observations depend on previous value, e.g., passengers this year similar to last year, but not similar to 50 years ago\n",
    "\n",
    "vs tabular ML (sklearn): data can be shuffled without altering statistical properties\n",
    "(\"independent and identically distributed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a15a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# airlines data\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "fig, ax = plot_series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49250e32",
   "metadata": {},
   "source": [
    "autocorrelation estimator shows adjacent values are very correlated!\n",
    "\n",
    "e.g., observations 1 period away almost perfectly correlate!\n",
    "\n",
    "(side note for stats aficionados: usually you apply acf after differencing or stationary series, this is for illustrating autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f511906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(y, lags=24, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison, here's what this plot would look like if you shuffle this data\n",
    "import numpy as np\n",
    "\n",
    "shuffled_data = np.random.permutation(y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(shuffled_data, lags=24, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d2be3",
   "metadata": {},
   "source": [
    "ML models (sktime) typically built on the assumption that data is i.i.d.  \n",
    "\n",
    "Time series models need to model temporally dependent data, trend, auto-correlation.  \n",
    "\n",
    "Common \"classical\" examples of time series models: Exponential Smoothing, ARIMA, Theta, etc.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eb0919",
   "metadata": {},
   "source": [
    "### Classical models, ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3b6e2",
   "metadata": {},
   "source": [
    "\"classical\" models standard for forecasting up until today!\n",
    "\n",
    "ML models with large parameters frequently underperform\n",
    "\n",
    "#### why? theory:\n",
    "\n",
    "auto-correlation reduces \"effective sample size\", roughly by 1 divided auto-correlation integral (!)\n",
    "\n",
    "ML and DL models need large sample size for training\n",
    "\n",
    "ineffective on low effective sample size (pre-training, global models can be way out - more later!)\n",
    "\n",
    "##### case in point:\n",
    "\n",
    "Monash Forecasting Repository. https://forecastingdata.org/\n",
    "\n",
    "30 datasets study. Classical time series regularly outperform the \"latest\" models (dataset dependent).\n",
    "\n",
    "Time series models often outperform more contemporary techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15050555",
   "metadata": {},
   "source": [
    "![Monash Forecasting Results](../images/monash_respository.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64422c9",
   "metadata": {},
   "source": [
    "However, there are compelling reasons to want to use ML for forecasting problems.  \n",
    "\n",
    " - Ability to recognize non-linear patterns\n",
    " - Ability to incorporate large amounts of non-time based exogenous data\n",
    " - Ability to capture global patterns among many time series\n",
    " - Recent successes using ML in forecasting competitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2de30",
   "metadata": {},
   "source": [
    "![](../images/m5_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1b0c8",
   "metadata": {},
   "source": [
    "![](../images/m5_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae34026",
   "metadata": {},
   "source": [
    "![](../images/m5_6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8a5e4",
   "metadata": {},
   "source": [
    "![](../images/ts_vs_ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b153e",
   "metadata": {},
   "source": [
    "Using ML for forecasting problems presents some issues.\n",
    "\n",
    "Data has to undergo pre-processing to make it usable for forecasting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd435d",
   "metadata": {},
   "source": [
    "### How to use both in practice? ``sktime``'s unified interface!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886d6e6",
   "metadata": {},
   "source": [
    "time series ecosystem:\n",
    "\n",
    "* fragmented, inhomogehous\n",
    "* **many** choices for time series models - in theory and in python packages\n",
    "* **inhomogenous interfaces**, pain to try/use different kinds of models\n",
    "\n",
    "``sktime`` provides easy, flexible, unified interface for time series modelling!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9042f773",
   "metadata": {},
   "source": [
    "![sktime](../images/unified_framework.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351de03",
   "metadata": {},
   "source": [
    "forecasting with ``sktime`` is simple!\n",
    "\n",
    "let's pretend we want to predict shampoo sales, typical business use case (and toy data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_shampoo_sales\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "y = load_shampoo_sales()\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y=y, test_size=6)\n",
    "fig, ax = plot_series(y_train, y_test, labels=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5eb83",
   "metadata": {},
   "source": [
    "as simple as this:\n",
    "\n",
    "1. specify model\n",
    "2. fit data\n",
    "3. predict\n",
    "\n",
    "(there's of course much more - evaluate, update/stream, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "# 1) Specify the model\n",
    "forecaster = AutoARIMA()\n",
    "\n",
    "# 2) Fit on train data\n",
    "# need to specify \"forecasting horizon\" = where to forecast\n",
    "fh = [1, 2, 3, 4, 5, 6] # Relative to y_train\n",
    "forecaster.fit(y_train, fh)\n",
    "\n",
    "# 3) Use fitted model to predict for a certain forecast horizon\n",
    "y_pred = forecaster.predict()\n",
    "\n",
    "fig, ax = plot_series(y_train, y_test, y_pred, labels=[\"train\", \"test\", \"pred\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9253a1c",
   "metadata": {},
   "source": [
    "this is the same for any model in sktime!\n",
    "\n",
    "classical (ARIMA etc), ML (reduction), deep learning (torch transformers), your own custom models..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad9f4f",
   "metadata": {},
   "source": [
    "* list predefined ones via `all_estimators` or check the API reference\n",
    "* add your own forecaster in third party repo via extension template\n",
    "* or use \"building blocks\" - first and third party - to build your custom model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a05ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(estimator_types=\"forecaster\", as_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bb1a6",
   "metadata": {},
   "source": [
    "### using tabular ML models for forecasting - \"reduction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64504f4",
   "metadata": {},
   "source": [
    "How to prepare time series data for ML?\n",
    "\n",
    "ML models don't have an innate ability to \"see\" previous samples in the data.\n",
    "\n",
    "Key idea: \"reduction\"\n",
    "\n",
    "![tabularization](../images/tabularization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8085ae",
   "metadata": {},
   "source": [
    "why \"reduction\"?\n",
    "\n",
    "as in \"reduce A to B\" = \"solve problem A (forecasting) with a solution for problem B (ML model)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fb551",
   "metadata": {},
   "source": [
    "in ``sktime``: all that changes is forecaster specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60120949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "\n",
    "# defining the reduction forecaster\n",
    "\n",
    "# takes an sktime regressor...\n",
    "regressor = HistGradientBoostingRegressor()\n",
    "\n",
    "# turn it into an sklearn forecaster!\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=16)\n",
    "\n",
    "# regressor be swapped with XBGoost, LightGBM, CatBoost, etc.\n",
    "\n",
    "# rest is the same as for any forecaster\n",
    "y_train, y_test = temporal_train_test_split(y=y, test_size=6)\n",
    "\n",
    "fh = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "y_pred = forecaster.fit_predict(y=y_train, fh=fh)\n",
    "\n",
    "# plotting and evaluation\n",
    "smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "\n",
    "title = f\"Gradient-boosted tree regressor - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e012496",
   "metadata": {},
   "source": [
    "* `regressor` algorithm can be any estimator that has a `fit` and `predict` method.  \n",
    "* `make_reduction` takes `sktime` `y`, and builds `sklearn` `X` and `y` by window/lagging\n",
    "\n",
    "but eyeball test: predictions are bad :-("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b1d81f",
   "metadata": {},
   "source": [
    "also does does not outperform an AutoARIMA model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0da963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import AutoARIMA\n",
    "\n",
    "arima_forecaster = AutoARIMA(sp=12, d=0, max_p=2, max_q=2, suppress_warnings=True)\n",
    "y_pred_arima = arima_forecaster.fit_predict(y=y_train, fh=fh)\n",
    "\n",
    "print(f\"Gradient-boosted tree regressor - sMAPE error: {smape(y_test, y_pred):.1%}\")\n",
    "print(f\"AutoARIMA - sMAPE error: {smape(y_test, y_pred_arima):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd54ca8",
   "metadata": {},
   "source": [
    "Why is the GBM under-performing?:\n",
    "\n",
    "* Gradient boosting trees cannot \"extrapolate\"\n",
    "* only forecast well within their observed range\n",
    "* time series was non-stationary, non-iid! future range was never observed!\n",
    "\n",
    "Solution: make (more) stationary by differencing\n",
    "\n",
    "easy to do in `sktime`: transformers (= transformation estimators)\n",
    "\n",
    "(note: wider concept than DL transformers, includes simple trafos like diff too)\n",
    "\n",
    "Let's see how to use the `Differencer` transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.difference import Differencer\n",
    "\n",
    "transformer = Differencer(lags=1)\n",
    "y_transform = transformer.fit_transform(y)\n",
    "fig, ax = plot_series(\n",
    "    y, y_transform, labels=[\"y\", \"y_diff\"], title=\"Difference transformation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = HistGradientBoostingRegressor()\n",
    "forecaster = make_reduction(regressor, strategy=\"direct\", window_length=16)\n",
    "forecaster_with_differencer = Differencer(lags=1) * forecaster\n",
    "\n",
    "# to do:  use transformed target forecaster for this step\n",
    "y_pred = forecaster_with_differencer.fit_predict(y=y_train, fh=fh)\n",
    "title = f\"Gradient-boosted tree regressor with difference transform - sMAPE error: {smape(y_test, y_pred):.1%}\"\n",
    "fig, ax = plot_series(\n",
    "    y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"], title=title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d585a642",
   "metadata": {},
   "source": [
    "We would like to take this example extend it to account for more complicated scenarios:  \n",
    "\n",
    " - Forecasting many time series simultaneously, many of which may be interrelated.\n",
    " - Producing features beyond using lag values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d28898c",
   "metadata": {},
   "source": [
    "### Panel Forecasting With ML and sktime\n",
    "\n",
    "The examples so far have focused on a single time series.\n",
    "\n",
    "many real world problems often involve multiple time series, many of which exist in a hierarchy.\n",
    "\n",
    "![hierarchical time series](../images/hierarchy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example hierarchical time series\n",
    "from pydata_utils import load_product_hierarchy\n",
    "\n",
    "y = load_product_hierarchy()\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492547cd",
   "metadata": {},
   "source": [
    "in, hierarchical time series usually:\n",
    "\n",
    "* individual time series related to one another\n",
    "* there are many of them\n",
    "* so effective sample size is large -> ML, DL benefits start to kick in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_index = y.droplevel(-1).index.unique()\n",
    "fig, ax = plot_series(*(y.loc[idx] for idx in product_index), labels=product_index, title=\"Product sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fd2baa",
   "metadata": {},
   "source": [
    "\"baseline\": individual time series modelled separately, \"local\"\n",
    "\n",
    "often, better approach: fit models to all of the time series jointly! \"global\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51dc8c",
   "metadata": {},
   "source": [
    "\"global\" approach successful used with ML models in competitions!\n",
    "\n",
    "Both \"local\" and \"global\" approach are straightforward in `sktime`:\n",
    "\n",
    "* \"global\" models fit to data as above, same interface `fit`, `predict`\n",
    "* single-series models are by default \"local\", fit to many time series - same API!\n",
    "* use `set_config` with `\"backend:parallel\"`, `backend:parallel:params` for \"embarrassing parallelization\" of local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train and test sets\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=4)\n",
    "\n",
    "# to do:  add in differencing w/ transformed targetforecaster\n",
    "regressor         = HistGradientBoostingRegressor()\n",
    "forecaster_local  = make_reduction(regressor, strategy=\"direct\", window_length=12, pooling=\"local\")\n",
    "forecaster_global = make_reduction(regressor, strategy=\"direct\", window_length=12, pooling=\"global\")\n",
    "forecaster_arima  = AutoARIMA(sp=12, d=0, max_p=2, max_q=2, suppress_warnings=True)\n",
    "\n",
    "hier_smape = MeanAbsolutePercentageError(symmetric=True, multilevel=\"raw_values\")\n",
    "\n",
    "y_pred_local = forecaster_local.fit_predict(y_train, fh=[1, 2, 3, 4])\n",
    "y_pred_global = forecaster_global.fit_predict(y_train, fh=[1, 2, 3, 4])\n",
    "y_pred_arima = forecaster_arima.fit_predict(y_train, fh = [1, 2, 3, 4])\n",
    "\n",
    "errors_local = hier_smape(y_test, y_pred_local)\n",
    "errors_global = hier_smape(y_test, y_pred_global)\n",
    "errors_arima = hier_smape(y_test, y_pred_arima)\n",
    "\n",
    "print(f\"Average sMAPE with local pooling: {errors_local.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with global pooling: {errors_global.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with AutoARIMA: {errors_arima.mean().iloc[0]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29182a",
   "metadata": {},
   "source": [
    "also available:\n",
    "\n",
    "* hierarchical reconciliation\n",
    "* configuring forecasters by node\n",
    "\n",
    "see advanced & hierarchical forecasting tutorial [link]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08ac9d",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Machine learning models often benefit from feature engineering beyond lags\n",
    "\n",
    "Examples:\n",
    " - Summary statistics for a given time series\n",
    " - Window statistics for a given time series\n",
    "\n",
    "Producing these features can easily be added to sktime pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1156ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "\n",
    "# arguments for the window transformer\n",
    "kwargs = {\n",
    "    \"lag_feature\": {\n",
    "        \"lag\": [1, 2, 3],\n",
    "        \"mean\": [[1, 3]],\n",
    "        \"std\": [[1, 10]],\n",
    "        \"kurt\": [[1, 10]]},\n",
    "    \"truncate\": 'bfill'\n",
    "}\n",
    "\n",
    "summarizer = WindowSummarizer(**kwargs, n_jobs = 1)\n",
    "window_data = summarizer.fit_transform(y_train)\n",
    "window_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec535719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window statistics can capture local patterns in a time series\n",
    "# not easily observed by lag values alone\n",
    "fig, ax = plot_series(*(window_data.loc[idx, 'Sales_kurt_1_10'] for idx in product_index), \n",
    "                      labels=product_index, title=\"Skewness of Product Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53100927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.summarize import WindowSummarizer\n",
    "\n",
    "# arguments for the window transformer\n",
    "kwargs = {\n",
    "    \"lag_feature\": {\n",
    "        \"lag\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "        \"mean\": [[1, 3]],\n",
    "        \"std\": [[1, 10]],\n",
    "        \"kurt\": [[1, 10]]},\n",
    "    \"truncate\": 'bfill'\n",
    "}\n",
    "\n",
    "forecaster_window = make_reduction(\n",
    "    regressor,\n",
    "    transformers=[WindowSummarizer(**kwargs, n_jobs=1)],\n",
    "    window_length=None,\n",
    "    strategy=\"direct\",\n",
    "    pooling=\"global\",\n",
    ")\n",
    "\n",
    "y_pred_global_window = forecaster_window.fit_predict(y_train, fh=[1, 2, 3, 4])\n",
    "errors_global_window = hier_smape(y_test, y_pred_global_window)\n",
    "\n",
    "print(f\"Average sMAPE with local pooling: {errors_local.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with global pooling: {errors_global.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with AutoARIMA: {errors_arima.mean().iloc[0]:.1%}\")\n",
    "print(f\"Average sMAPE with window transformations: {errors_global_window.mean().iloc[0]:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdee28d",
   "metadata": {},
   "source": [
    "As we can see in the above example, we've now beat the AutoARIMA baseline.  \n",
    "\n",
    "Global forecasting also has faster fitting times than local forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d293ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit forecaster_window.fit(y_train, fh=[1, 2, 3, 4])\n",
    "%timeit forecaster_arima.fit(y_train, fh=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71a171",
   "metadata": {},
   "source": [
    "### Trade-offs - stats, ML, DL, foundation models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bec292",
   "metadata": {},
   "source": [
    "Some \"rule of thumb\" recommendations:\n",
    "\n",
    "* always try simpler models first\n",
    "* always compare \"simpler\" to \"complex\"\n",
    "* always compare on your own use case, benchmark performance and KPI (e.g., interpretability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ba437",
   "metadata": {},
   "source": [
    "| model type   | example | best on eff. sample size | complexity | interpretability | comments |\n",
    "|----------|---------------|-------|-------|-------|-------|\n",
    "| naive baselines  | naive carry-forward | minimal | minimal | obvious | always include these! Point of comparison! |\n",
    "| classical        | ARIMA, Exp. smoothing | small, single series | low | usually glass box | low-cost, well-understood, may underperform |\n",
    "| ML, reduction    | direct reducer | medium, multiple series | mid | black box | may have feature importance, very off-shelf |\n",
    "| DL, transformers | LTSF-Linear, NBEATS | varies (pretraining) | high | black box | can be pre-trained, tuned; some interpretability |\n",
    "| genAI/foundation | various vendors | (unclear, tbd) | high | black box | typically only API access, customer lock-in |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e100d49",
   "metadata": {},
   "source": [
    "**Advice: combine with pipelines!** - detrending, deseasonalizing, feature engineering can give huge performance boosts!\n",
    "\n",
    "All model types can be combined with pipelines in the `sktime` interface. `Detrender() * Deseasonalizer(sp=12) * mymodel`\n",
    "\n",
    "see [advanced forecasting tutorials at ODSC 2023](https://github.com/sktime/sktime-tutorial-europython-2023) or [pycon Prague 2023](https://github.com/sktime/sktime-workshop-pydata-prague-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d20da",
   "metadata": {},
   "source": [
    "**Advice: benchmarking is important** - test on your own data! (new models: also on common benchmark cases)\n",
    "\n",
    "Do \"ablation testing\" - test complex models against simpler models (e.g., simpler pipeline, less complex model)\n",
    "\n",
    "see [sktime benchmarking tutorial at pycon Prague](https://github.com/sktime/sktime-workshop-pydata-prague-2023)\n",
    "\n",
    "Big caveat with pre-trained DL and genAI models:\n",
    "\n",
    "* what data could these have been trained on? in commercial solutions, often unknown\n",
    "* testing performance on public benchmark datasets might result in overoptimism..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6680b95",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "What did we cover today?  \n",
    "\n",
    " - Time series models and machine learning models can both successfuly be used for forecasting\n",
    " - Time series models are easier to use \"out of the box\" on a single time series\n",
    " - ML models can make more sense for modeling time series simultaneously\n",
    " - You should expect to do feature engineering when time series modeling with ML\n",
    " - `sktime` provides a helpful interface for unifying the workflows for the tasks described today"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec542bb",
   "metadata": {},
   "source": [
    "Further reading:\n",
    "\n",
    "* main `sktime` [tutorials on binder](https://mybinder.org/v2/gh/sktime/sktime/main?filepath=examples)\n",
    "* recorded [video tutorials](https://www.youtube.com/playlist?list=PLKs3UgGjlWHqNzu0LEOeLKvnjvvest2d0)\n",
    "* find a bug or type? [tutorial feedback thread](https://github.com/sktime/sktime/issues/1447)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61c5c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92f2f1",
   "metadata": {},
   "source": [
    "## Join sktime!\n",
    "\n",
    "### Vision statement\n",
    "\n",
    "* an easy-to-use, easy-to-extend, comprehensive **python framework** for ML and AI with time series\n",
    "* **open source, permissive license, free to use**\n",
    "* **openly and transparently governed**\n",
    "* **friendly, responsive, kind and inclusive** community, with an active commitment to ensure fairness and equal opportunity\n",
    "* an academically and commercially **neutral space**, with an **ecosystem integration** ambition and neutral point of view\n",
    "* an **educational platform**, providing mentoring and upskilling opportunities for all career stages, especially early career\n",
    "\n",
    "**EVERYONE CAN JOIN! EVERYONE CAN BECOME A COMMUNITY LEADER!**\n",
    "\n",
    "* join our community discord ([join link](https://discord.com/invite/54ACzaFsn7))!\n",
    "    * **help-desk for Q&A** and getting started as a user!\n",
    "    * **dev-chat** for help getting started with open source!\n",
    "        * contributor [getting started guide](https://github.com/sktime/sktime/issues/1147)\n",
    "        * [good first issues](https://github.com/sktime/sktime/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)\n",
    "* join `sktime`'s user representatives or governance working group\n",
    "    * register as a user ([form](https://forms.gle/eVuzrCjKDRupxawL7)) - roadmap, bugfix prio, elections\n",
    "        * [roadmap 2023-2024 planning](https://github.com/sktime/sktime/issues/4691)\n",
    "    * join [council sessions](https://github.com/sktime/community-org/tree/main/community_council/previous_meetings) and give input\n",
    "* sktime **mentoring programme**: [link](github.com/sktime/mentoring)\n",
    "\n",
    "Events & meetups:\n",
    "\n",
    "* regular **community collaboration sessions**\n",
    "    * meet-ups Fri 3pm UTC on [discord](https://discord.com/invite/54ACzaFsn7)\n",
    "* multiple **Sprints and Dev Days** per year\n",
    "    * watch [LinkedIn](https://www.linkedin.com/company/scikit-time/) for announcements!\n",
    "\n",
    "Support us if `sktime` has generated value for you!\n",
    "\n",
    "* star us on [GitHub](https://github.com/sktime/sktime)\n",
    "* follow us on [LinkedIn](https://www.linkedin.com/company/scikit-time/)\n",
    "* donate! Every cent helps the time series ecosystem ([GitHub sponsors](https://github.com/sponsors/sktime))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3993d394",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e21b00",
   "metadata": {},
   "source": [
    "## Thank you for your attention\n",
    "\n",
    "<img src=\"./img/sktime-logo-text-horizontal.jpg\" alt=\"Sktime Logo\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768a62c",
   "metadata": {},
   "source": [
    "---\n",
    "### Credits: notebook\n",
    "\n",
    "JonathanBechtel, fkiraly\n",
    "\n",
    "based on notebooks by marrov, fkiraly, danbartl, mloning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe11380",
   "metadata": {},
   "source": [
    "---\n",
    "### Credits: sktime\n",
    "\n",
    "#### many thanks to [all `sktime` contributors](https://www.sktime.net/en/latest/about/contributors.html)!\n",
    "Citations & credits in academic research papers:\n",
    "\n",
    "`sktime` toolbox:\n",
    " [sktime: A unified interface for machine learning with time series](https://arxiv.org/abs/1909.07872)\n",
    "\n",
    "`sktime` design principles: [Designing machine learning toolboxes: Concepts, principles and patterns](https://arxiv.org/abs/2101.04938)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
